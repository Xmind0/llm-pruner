`torch_dtype` is deprecated! Use `dtype` instead!
正在 cuda 上加载 daryl149/llama-2-7b-chat-hf ...
使用旋转矩阵计算方法: fisher
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 132.95it/s]
`torch_dtype` is deprecated! Use `dtype` instead!
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: Both `past_key_value` and `past_key_values` are set for `LlamaAttention.forward`. Using `past_key_values=None` and ignoring deprecated `past_key_value=None`.
  return forward_call(*args, **kwargs)
正在加载校准数据 wikitext2...
正在融合 LayerNorms...
从 4096 切片到 -> 3272
正在使用 fisher 方法旋转和切片...
Rotating and slicing:   0%|          | 0/32 [00:00<?, ?layer/s]Rotating and slicing:   3%|▎         | 1/32 [02:46<1:26:03, 166.56s/layer]Rotating and slicing:   6%|▋         | 2/32 [05:26<1:21:20, 162.69s/layer]Rotating and slicing:   9%|▉         | 3/32 [08:01<1:16:51, 159.03s/layer]Rotating and slicing:  12%|█▎        | 4/32 [10:30<1:12:20, 155.02s/layer]Rotating and slicing:  16%|█▌        | 5/32 [12:53<1:07:53, 150.87s/layer]Rotating and slicing:  19%|█▉        | 6/32 [15:11<1:03:31, 146.58s/layer]Rotating and slicing:  22%|██▏       | 7/32 [17:24<59:13, 142.16s/layer]  Rotating and slicing:  25%|██▌       | 8/32 [19:33<55:04, 137.69s/layer]Rotating and slicing:  28%|██▊       | 9/32 [21:36<51:02, 133.15s/layer]Rotating and slicing:  31%|███▏      | 10/32 [23:34<47:09, 128.64s/layer]Rotating and slicing:  34%|███▍      | 11/32 [25:28<43:26, 124.10s/layer]Rotating and slicing:  38%|███▊      | 12/32 [27:18<39:53, 119.65s/layer]Rotating and slicing:  41%|████      | 13/32 [29:02<36:26, 115.07s/layer]Rotating and slicing:  44%|████▍     | 14/32 [30:42<33:10, 110.56s/layer]Rotating and slicing:  47%|████▋     | 15/32 [32:18<30:01, 105.97s/layer]Rotating and slicing:  50%|█████     | 16/32 [33:48<27:02, 101.39s/layer]Rotating and slicing:  53%|█████▎    | 17/32 [35:14<24:12, 96.80s/layer] Rotating and slicing:  56%|█████▋    | 18/32 [36:36<21:32, 92.31s/layer]Rotating and slicing:  59%|█████▉    | 19/32 [37:54<19:02, 87.89s/layer]Rotating and slicing:  62%|██████▎   | 20/32 [39:07<16:42, 83.51s/layer]Rotating and slicing:  66%|██████▌   | 21/32 [40:16<14:30, 79.13s/layer]Rotating and slicing:  69%|██████▉   | 22/32 [41:21<12:27, 74.79s/layer]Rotating and slicing:  72%|███████▏  | 23/32 [42:21<10:34, 70.54s/layer]Rotating and slicing:  75%|███████▌  | 24/32 [43:18<08:50, 66.31s/layer]Rotating and slicing:  78%|███████▊  | 25/32 [44:10<07:14, 62.09s/layer]Rotating and slicing:  81%|████████▏ | 26/32 [44:58<05:47, 57.86s/layer]Rotating and slicing:  84%|████████▍ | 27/32 [45:42<04:28, 53.67s/layer]Rotating and slicing:  88%|████████▊ | 28/32 [46:22<03:18, 49.50s/layer]Rotating and slicing:  91%|█████████ | 29/32 [46:57<02:16, 45.34s/layer]Rotating and slicing:  94%|█████████▍| 30/32 [47:29<01:22, 41.19s/layer]Rotating and slicing:  97%|█████████▋| 31/32 [47:56<00:37, 37.05s/layer]Rotating and slicing: 100%|██████████| 32/32 [48:20<00:00, 32.92s/layer]Rotating and slicing: 100%|██████████| 32/32 [48:20<00:00, 90.63s/layer]
成功！模型已完成切片。
模型已保存至 sliced_llama-2-7b-chat-hf.pt
正在评估困惑度...
切片后 wikitext2 困惑度: 8.489930152893066
`torch_dtype` is deprecated! Use `dtype` instead!
正在 cuda 上加载 daryl149/llama-2-7b-chat-hf ...
使用旋转矩阵计算方法: pca
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 133.19it/s]
`torch_dtype` is deprecated! Use `dtype` instead!
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
正在加载校准数据 wikitext2...
正在融合 LayerNorms...
从 4096 切片到 -> 3272
正在使用 pca 方法旋转和切片...
Rotating and slicing:   0%|          | 0/32 [00:00<?, ?layer/s]/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: Both `past_key_value` and `past_key_values` are set for `LlamaAttention.forward`. Using `past_key_values=None` and ignoring deprecated `past_key_value=None`.
  return forward_call(*args, **kwargs)
Rotating and slicing:   3%|▎         | 1/32 [00:19<10:14, 19.81s/layer]Rotating and slicing:   6%|▋         | 2/32 [00:37<09:24, 18.83s/layer]Rotating and slicing:   9%|▉         | 3/32 [00:54<08:41, 17.97s/layer]Rotating and slicing:  12%|█▎        | 4/32 [01:11<08:08, 17.46s/layer]Rotating and slicing:  16%|█▌        | 5/32 [01:28<07:49, 17.39s/layer]Rotating and slicing:  19%|█▉        | 6/32 [01:45<07:29, 17.27s/layer]Rotating and slicing:  22%|██▏       | 7/32 [02:02<07:07, 17.11s/layer]Rotating and slicing:  25%|██▌       | 8/32 [02:19<06:50, 17.11s/layer]Rotating and slicing:  28%|██▊       | 9/32 [02:36<06:33, 17.12s/layer]Rotating and slicing:  31%|███▏      | 10/32 [02:53<06:13, 16.98s/layer]Rotating and slicing:  34%|███▍      | 11/32 [03:10<05:56, 16.97s/layer]Rotating and slicing:  38%|███▊      | 12/32 [03:27<05:37, 16.88s/layer]Rotating and slicing:  41%|████      | 13/32 [03:44<05:22, 16.95s/layer]Rotating and slicing:  44%|████▍     | 14/32 [04:01<05:04, 16.90s/layer]Rotating and slicing:  47%|████▋     | 15/32 [04:18<04:47, 16.94s/layer]Rotating and slicing:  50%|█████     | 16/32 [04:35<04:31, 16.96s/layer]Rotating and slicing:  53%|█████▎    | 17/32 [04:51<04:13, 16.93s/layer]Rotating and slicing:  56%|█████▋    | 18/32 [05:09<03:58, 17.00s/layer]Rotating and slicing:  59%|█████▉    | 19/32 [05:26<03:41, 17.07s/layer]Rotating and slicing:  62%|██████▎   | 20/32 [05:43<03:24, 17.05s/layer]Rotating and slicing:  66%|██████▌   | 21/32 [06:00<03:07, 17.03s/layer]Rotating and slicing:  69%|██████▉   | 22/32 [06:17<02:50, 17.03s/layer]Rotating and slicing:  72%|███████▏  | 23/32 [06:34<02:33, 17.01s/layer]Rotating and slicing:  75%|███████▌  | 24/32 [06:51<02:15, 16.94s/layer]Rotating and slicing:  78%|███████▊  | 25/32 [07:08<01:58, 16.99s/layer]Rotating and slicing:  81%|████████▏ | 26/32 [07:25<01:42, 17.01s/layer]Rotating and slicing:  84%|████████▍ | 27/32 [07:42<01:24, 16.94s/layer]Rotating and slicing:  88%|████████▊ | 28/32 [07:59<01:08, 17.01s/layer]Rotating and slicing:  91%|█████████ | 29/32 [08:16<00:51, 17.03s/layer]Rotating and slicing:  94%|█████████▍| 30/32 [08:33<00:34, 17.10s/layer]Rotating and slicing:  97%|█████████▋| 31/32 [08:50<00:17, 17.07s/layer]Rotating and slicing: 100%|██████████| 32/32 [09:07<00:00, 17.05s/layer]Rotating and slicing: 100%|██████████| 32/32 [09:07<00:00, 17.11s/layer]
成功！模型已完成切片。
模型已保存至 sliced_llama-2-7b-chat-hf.pt
正在评估困惑度...
切片后 wikitext2 困惑度: 8.565083503723145
`torch_dtype` is deprecated! Use `dtype` instead!
正在 cuda 上加载 daryl149/llama-2-7b-chat-hf ...
使用旋转矩阵计算方法: fisher
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 127.99it/s]
`torch_dtype` is deprecated! Use `dtype` instead!
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: Both `past_key_value` and `past_key_values` are set for `LlamaAttention.forward`. Using `past_key_values=None` and ignoring deprecated `past_key_value=None`.
  return forward_call(*args, **kwargs)
正在加载校准数据 wikitext2...
正在融合 LayerNorms...
从 4096 切片到 -> 2048
正在使用 fisher 方法旋转和切片...
Rotating and slicing:   0%|          | 0/32 [00:00<?, ?layer/s]Rotating and slicing:   3%|▎         | 1/32 [02:45<1:25:45, 166.00s/layer]Rotating and slicing:   6%|▋         | 2/32 [05:25<1:21:06, 162.22s/layer]Rotating and slicing:   9%|▉         | 3/32 [07:59<1:16:36, 158.48s/layer]Rotating and slicing:  12%|█▎        | 4/32 [10:28<1:12:11, 154.68s/layer]Rotating and slicing:  16%|█▌        | 5/32 [12:52<1:07:50, 150.77s/layer]Rotating and slicing:  19%|█▉        | 6/32 [15:11<1:03:34, 146.73s/layer]Rotating and slicing:  22%|██▏       | 7/32 [17:24<59:21, 142.47s/layer]  Rotating and slicing:  25%|██▌       | 8/32 [19:33<55:14, 138.09s/layer]Rotating and slicing:  28%|██▊       | 9/32 [21:36<51:10, 133.49s/layer]Rotating and slicing:  31%|███▏      | 10/32 [23:35<47:14, 128.82s/layer]Rotating and slicing:  34%|███▍      | 11/32 [25:28<43:25, 124.07s/layer]Rotating and slicing:  38%|███▊      | 12/32 [27:16<39:44, 119.25s/layer]Rotating and slicing:  41%|████      | 13/32 [28:59<36:12, 114.33s/layer]Rotating and slicing:  44%|████▍     | 14/32 [30:38<32:50, 109.45s/layer]Rotating and slicing:  47%|████▋     | 15/32 [32:11<29:38, 104.61s/layer]Rotating and slicing:  50%|█████     | 16/32 [33:40<26:36, 99.80s/layer] Rotating and slicing:  53%|█████▎    | 17/32 [35:04<23:47, 95.15s/layer]Rotating and slicing:  56%|█████▋    | 18/32 [36:24<21:09, 90.68s/layer]Rotating and slicing:  59%|█████▉    | 19/32 [37:40<18:42, 86.32s/layer]Rotating and slicing:  62%|██████▎   | 20/32 [38:52<16:23, 81.99s/layer]Rotating and slicing:  66%|██████▌   | 21/32 [40:00<14:14, 77.68s/layer]Rotating and slicing:  69%|██████▉   | 22/32 [41:04<12:14, 73.46s/layer]Rotating and slicing:  72%|███████▏  | 23/32 [42:03<10:23, 69.24s/layer]Rotating and slicing:  75%|███████▌  | 24/32 [42:58<08:40, 65.07s/layer]Rotating and slicing:  78%|███████▊  | 25/32 [43:50<07:06, 60.94s/layer]Rotating and slicing:  81%|████████▏ | 26/32 [44:37<05:40, 56.83s/layer]Rotating and slicing:  84%|████████▍ | 27/32 [45:20<04:23, 52.68s/layer]Rotating and slicing:  88%|████████▊ | 28/32 [45:59<03:14, 48.57s/layer]Rotating and slicing:  91%|█████████ | 29/32 [46:34<02:13, 44.45s/layer]Rotating and slicing:  94%|█████████▍| 30/32 [47:04<01:20, 40.29s/layer]Rotating and slicing:  97%|█████████▋| 31/32 [47:31<00:36, 36.14s/layer]Rotating and slicing: 100%|██████████| 32/32 [47:53<00:00, 31.99s/layer]Rotating and slicing: 100%|██████████| 32/32 [47:53<00:00, 89.80s/layer]
成功！模型已完成切片。
模型已保存至 sliced_llama-2-7b-chat-hf.pt
正在评估困惑度...
切片后 wikitext2 困惑度: 23.414573669433594
`torch_dtype` is deprecated! Use `dtype` instead!
正在 cuda 上加载 daryl149/llama-2-7b-chat-hf ...
使用旋转矩阵计算方法: pca
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 86.51it/s]
`torch_dtype` is deprecated! Use `dtype` instead!
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
正在加载校准数据 wikitext2...
正在融合 LayerNorms...
从 4096 切片到 -> 2048
正在使用 pca 方法旋转和切片...
Rotating and slicing:   0%|          | 0/32 [00:00<?, ?layer/s]/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: Both `past_key_value` and `past_key_values` are set for `LlamaAttention.forward`. Using `past_key_values=None` and ignoring deprecated `past_key_value=None`.
  return forward_call(*args, **kwargs)
Rotating and slicing:   3%|▎         | 1/32 [00:18<09:48, 18.97s/layer]Rotating and slicing:   6%|▋         | 2/32 [00:36<09:07, 18.24s/layer]Rotating and slicing:   9%|▉         | 3/32 [00:53<08:24, 17.39s/layer]Rotating and slicing:  12%|█▎        | 4/32 [01:09<07:51, 16.83s/layer]Rotating and slicing:  16%|█▌        | 5/32 [01:25<07:27, 16.58s/layer]Rotating and slicing:  19%|█▉        | 6/32 [01:41<07:09, 16.52s/layer]Rotating and slicing:  22%|██▏       | 7/32 [01:57<06:51, 16.46s/layer]Rotating and slicing:  25%|██▌       | 8/32 [02:14<06:36, 16.53s/layer]Rotating and slicing:  28%|██▊       | 9/32 [02:30<06:19, 16.48s/layer]Rotating and slicing:  31%|███▏      | 10/32 [02:47<06:03, 16.54s/layer]Rotating and slicing:  34%|███▍      | 11/32 [03:04<05:46, 16.52s/layer]Rotating and slicing:  38%|███▊      | 12/32 [03:20<05:29, 16.47s/layer]Rotating and slicing:  41%|████      | 13/32 [03:36<05:12, 16.44s/layer]Rotating and slicing:  44%|████▍     | 14/32 [03:53<04:55, 16.44s/layer]Rotating and slicing:  47%|████▋     | 15/32 [04:09<04:38, 16.41s/layer]Rotating and slicing:  50%|█████     | 16/32 [04:25<04:22, 16.39s/layer]Rotating and slicing:  53%|█████▎    | 17/32 [04:42<04:05, 16.35s/layer]Rotating and slicing:  56%|█████▋    | 18/32 [04:58<03:47, 16.26s/layer]Rotating and slicing:  59%|█████▉    | 19/32 [05:14<03:31, 16.28s/layer]Rotating and slicing:  62%|██████▎   | 20/32 [05:30<03:15, 16.25s/layer]Rotating and slicing:  66%|██████▌   | 21/32 [05:47<02:58, 16.27s/layer]Rotating and slicing:  69%|██████▉   | 22/32 [06:03<02:42, 16.23s/layer]Rotating and slicing:  72%|███████▏  | 23/32 [06:19<02:26, 16.25s/layer]Rotating and slicing:  75%|███████▌  | 24/32 [06:35<02:09, 16.23s/layer]Rotating and slicing:  78%|███████▊  | 25/32 [06:51<01:53, 16.23s/layer]Rotating and slicing:  81%|████████▏ | 26/32 [07:08<01:37, 16.30s/layer]Rotating and slicing:  84%|████████▍ | 27/32 [07:24<01:21, 16.22s/layer]Rotating and slicing:  88%|████████▊ | 28/32 [07:40<01:05, 16.27s/layer]Rotating and slicing:  91%|█████████ | 29/32 [07:57<00:48, 16.29s/layer]Rotating and slicing:  94%|█████████▍| 30/32 [08:13<00:32, 16.31s/layer]Rotating and slicing:  97%|█████████▋| 31/32 [08:29<00:16, 16.30s/layer]Rotating and slicing: 100%|██████████| 32/32 [08:46<00:00, 16.31s/layer]Rotating and slicing: 100%|██████████| 32/32 [08:46<00:00, 16.44s/layer]
成功！模型已完成切片。
模型已保存至 sliced_llama-2-7b-chat-hf.pt
正在评估困惑度...
切片后 wikitext2 困惑度: 25.88920021057129
